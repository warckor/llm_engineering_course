# üì∞ Web Summarizer - DevOps News

Este proyecto implementa un sistema de web scraping y resumen autom√°tico de noticias de DevOps utilizando diferentes modelos de inteligencia artificial. El sistema est√° dise√±ado para extraer contenido de sitios web especializados en DevOps y generar res√∫menes concisos utilizando modelos de lenguaje avanzados.

## üéØ Objetivo

Desarrollar una herramienta que automatice la extracci√≥n y el resumen de contenido web especializado en DevOps, comparando el rendimiento de diferentes modelos de IA:

- **Google Gemini 2.5 Flash** (API)
- **LMStudio** (servidor local)
- **Ollama** (modelo local)

## üõ†Ô∏è Tecnolog√≠as Utilizadas

- **Python 3.13+**
- **Beautiful Soup 4** - Para web scraping y parsing HTML
- **Requests** - Para realizar peticiones HTTP
- **Google Generative AI** - Para integraci√≥n con Gemini
- **OpenAI API** - Para LMStudio
- **Ollama Python Client** - Para modelos locales
- **python-dotenv** - Para gesti√≥n de variables de entorno
- **IPython** - Para visualizaci√≥n mejorada en notebooks

## üìÅ Estructura del Proyecto

```text
01-web-summarizer/
‚îú‚îÄ‚îÄ .env                           # Variables de entorno (API keys)
‚îú‚îÄ‚îÄ .python-version               # Versi√≥n de Python requerida
‚îú‚îÄ‚îÄ pyproject.toml               # Configuraci√≥n del proyecto y dependencias
‚îú‚îÄ‚îÄ uv.lock                      # Lock file para reproducibilidad
‚îú‚îÄ‚îÄ README.md                    # Este archivo
‚îú‚îÄ‚îÄ devops_news_gemini.ipynb     # Implementaci√≥n con Google Gemini
‚îú‚îÄ‚îÄ devops_news_lmstudio.ipynb   # Implementaci√≥n con LMStudio
‚îî‚îÄ‚îÄ devops_news_ollama.ipynb     # Implementaci√≥n con Ollama
```

## üöÄ Funcionalidades Principales

### Clase Scrapper

- **Extracci√≥n de contenido web**: Obtiene HTML de URLs especificadas
- **Limpieza autom√°tica**: Remueve elementos irrelevantes (scripts, estilos, navegaci√≥n)
- **Parsing inteligente**: Extrae t√≠tulo y contenido textual limpio
- **Gesti√≥n de errores**: Manejo robusto de errores de red y parsing

### Implementaciones por Modelo

#### 1. Google Gemini (devops_news_gemini.ipynb)

- Utiliza la API de Google Generative AI
- Modelo: `gemini-2.5-flash`
- Configuraci√≥n optimizada para res√∫menes concisos
- Formato de salida en Markdown

#### 2. LMStudio (devops_news_lmstudio.ipynb)

- Conexi√≥n a servidor local de LMStudio
- Compatible con modelos OpenAI
- Flexibilidad para diferentes modelos locales
- Control total sobre par√°metros de generaci√≥n

#### 3. Ollama (devops_news_ollama.ipynb)

- Integraci√≥n nativa con Ollama
- Modelos completamente locales
- Sin dependencia de APIs externas
- Ideal para privacidad y desarrollo offline

## ‚öôÔ∏è Configuraci√≥n

### 1. Instalaci√≥n de Dependencias

```bash
# Usando uv (recomendado)
uv sync

# O usando pip tradicional
pip install -r requirements.txt
```

### 2. Variables de Entorno

Crear un archivo `.env` en la ra√≠z del proyecto:

```env
# Para Google Gemini
GEMINI_API_KEY=tu_api_key_de_gemini

# Para LMStudio (si usas servidor local)
LMSTUDIO_BASE_URL=http://localhost:1234/v1
LMSTUDIO_API_KEY=lm-studio

# Para Ollama (si usas servidor remoto)
OLLAMA_HOST=http://localhost:11434
```

### 3. Configuraci√≥n de Modelos Locales

#### LMStudio

1. Instalar LMStudio desde [https://lmstudio.ai/](https://lmstudio.ai/)
2. Descargar un modelo compatible (ej: Llama 2, Code Llama)
3. Iniciar el servidor local en puerto 1234

#### Ollama

1. Instalar Ollama desde [https://ollama.ai/](https://ollama.ai/)
2. Descargar modelos: `ollama pull llama2`
3. El servidor se ejecuta autom√°ticamente en puerto 11434

## üìä Uso

### Ejecuci√≥n B√°sica

1. **Abrir el notebook deseado** en Jupyter Lab/VSCode
2. **Configurar la URL objetivo** (por defecto: DevOpsCube)
3. **Ejecutar las celdas secuencialmente**
4. **Revisar el resumen generado**

### Ejemplo de Uso

```python
# Inicializar el scrapper
scrapper = Scrapper()
content = scrapper.get_content("https://devopscube.com/blog/")

# Procesar con IA (ejemplo con Gemini)
response = client.models.generate_content(
    model=MODEL,
    contents=f"Resume el siguiente contenido: {content.body}"
)

# Mostrar resultado
display(Markdown(response.text))
```

## üîç Caracter√≠sticas del Scrapper

- **Filtrado inteligente**: Remueve autom√°ticamente elementos HTML irrelevantes
- **Extracci√≥n de texto limpio**: Obtiene contenido textual sin formato
- **Gesti√≥n de t√≠tulos**: Extrae y preserva t√≠tulos de p√°gina
- **Handling de errores**: Gesti√≥n robusta de errores de red y parsing
- **Configurabilidad**: F√°cil adaptaci√≥n a diferentes sitios web

## üìà Casos de Uso

1. **Monitoreo de noticias DevOps**: Res√∫menes autom√°ticos de blogs especializados
2. **Investigaci√≥n de tendencias**: An√°lisis de contenido de m√∫ltiples fuentes
3. **Boletines informativos**: Generaci√≥n autom√°tica de newsletters
4. **An√°lisis comparativo**: Evaluaci√≥n de diferentes modelos de IA
5. **Prototipado r√°pido**: Base para sistemas de resumen m√°s complejos

## üéì Aprendizajes del Curso

Este proyecto forma parte del m√≥dulo de introducci√≥n a la inteligencia artificial generativa, donde se exploran:

- **Integraci√≥n de APIs de IA**: Trabajo con diferentes proveedores (Google, OpenAI)
- **Modelos locales vs. en la nube**: Comparaci√≥n de ventajas y limitaciones
- **Web scraping responsable**: T√©cnicas de extracci√≥n de contenido web
- **Prompt engineering**: Optimizaci√≥n de prompts para res√∫menes de calidad
- **Gesti√≥n de entornos**: Configuraci√≥n de proyectos con m√∫ltiples dependencias

## üìù Notas T√©cnicas

- **Compatibilidad**: Requiere Python 3.13 o superior
- **Dependencias**: Todas las dependencias est√°n especificadas en `pyproject.toml`
- **Seguridad**: Las API keys deben mantenerse en `.env` y nunca commitear al repositorio
- **Rendimiento**: Los modelos locales pueden ser m√°s lentos pero ofrecen mayor privacidad
- **Rate limiting**: Considerar l√≠mites de API al usar servicios externos
